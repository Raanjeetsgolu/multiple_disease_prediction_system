{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "\n",
        "*   Supervisied machine learning algorithm\n",
        "*   use for both regression and classification ( but mainly use for classification task )\n"
      ],
      "metadata": {
        "id": "Juqf-KxKikxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***kernels***\n",
        "\n",
        "kernel are mathematical funciton used to transform the data into higher dimension\n",
        "\n",
        "*   Enable svm to handle complex and non-linear data\n",
        "- Important types of Kernels\n",
        "  - Linear\n",
        "  - Polynomial\n",
        "  - Radial Basis Function (RBF)\n",
        "  - Sigmoid\n",
        "\n",
        "\n",
        "1. Linear Kernel\n",
        "  K(x1,x2)= x1^TX2\n",
        "\n",
        "2. Polynomial Kernels\n",
        "  K(x1, x2) = (x1^T X2 +r)^d\n",
        "\n",
        "3. Radial Basis Function (rbf) Kernel\n",
        "  K(x1, x2) = exp(-garrma . || x1 - x2 ||^2)\n",
        "\n",
        "4. Sigmoid Kernel\n",
        "  K(x1, x2) = tanh(gamma.x1^T x2 + r)\n",
        "\n",
        "- kernal choice based on Nature of dataset and amount of data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k6xyswVY92c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vectors are the point closer to hyperplane"
      ],
      "metadata": {
        "id": "uHWl-20qiOTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss FUnction**\n",
        "\n"
      ],
      "metadata": {
        "id": "m2etZM9PGdw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages**\n",
        "\n",
        "Avoiding the curse of dimensionality better than many other classifier\n",
        "1.   Works well with smaller datasets\n",
        "2.   Works efficiently when there is a clear margin of separation\n",
        "3.   Works well with high dimensional data\n",
        "\n",
        "**Disadvantages**\n",
        "\n",
        "\n",
        "\n",
        "1.   Not suitable for large datasets as the training time is higher The time complexity can range from O(n^2) to O(n^3) making it less practical for very large datasets\n",
        "2.   Not suitable for noiser datasets with overlapping classes\n",
        "\n"
      ],
      "metadata": {
        "id": "BSNM0GX0hOM5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kfrP8pS-hNTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eV1bVQ3hJnL"
      },
      "outputs": [],
      "source": []
    }
  ]
}